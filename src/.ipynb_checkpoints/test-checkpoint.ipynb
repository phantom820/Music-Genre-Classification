{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>data/FMA/Wav/099096.wav</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>data/FMA/Wav/145457.wav</td>\n",
       "      <td>Instrumental</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>data/FMA/Wav/071248.wav</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>data/FMA/Wav/067357.wav</td>\n",
       "      <td>Pop</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>data/FMA/Wav/098569.wav</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3840</th>\n",
       "      <td>data/FMA/Wav/004779.wav</td>\n",
       "      <td>Rock</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3576</th>\n",
       "      <td>data/FMA/Wav/140788.wav</td>\n",
       "      <td>Folk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>data/FMA/Wav/149099.wav</td>\n",
       "      <td>Pop</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     filename         genre  genre id\n",
       "2564  data/FMA/Wav/099096.wav       Hip-Hop         3\n",
       "468   data/FMA/Wav/145457.wav  Instrumental         4\n",
       "965   data/FMA/Wav/071248.wav       Hip-Hop         3\n",
       "1701  data/FMA/Wav/067357.wav           Pop         6\n",
       "2883  data/FMA/Wav/098569.wav       Hip-Hop         3\n",
       "3840  data/FMA/Wav/004779.wav          Rock         7\n",
       "3576  data/FMA/Wav/140788.wav          Folk         2\n",
       "1899  data/FMA/Wav/149099.wav           Pop         6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"data/FMA/Features/small_tracks2.csv\")\n",
    "data.sample(frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7997, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>genre</th>\n",
       "      <th>genre id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/GTZAN/disco/disco.00075.wav</td>\n",
       "      <td>disco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/GTZAN/disco/disco.00092.wav</td>\n",
       "      <td>disco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/GTZAN/disco/disco.00012.wav</td>\n",
       "      <td>disco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/GTZAN/disco/disco.00021.wav</td>\n",
       "      <td>disco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/GTZAN/disco/disco.00014.wav</td>\n",
       "      <td>disco</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filename  genre  genre id\n",
       "0  data/GTZAN/disco/disco.00075.wav  disco         3\n",
       "1  data/GTZAN/disco/disco.00092.wav  disco         3\n",
       "2  data/GTZAN/disco/disco.00012.wav  disco         3\n",
       "3  data/GTZAN/disco/disco.00021.wav  disco         3\n",
       "4  data/GTZAN/disco/disco.00014.wav  disco         3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_representation():\n",
    "    dataframe={\"filename\":[],\"genre\":[],\"genre id\":[]}\n",
    "    for folder in glob.glob(\"data/GTZAN/*\"):\n",
    "        for file in glob.glob(folder+\"/*\"):\n",
    "            dataframe[\"genre\"].append(folder.split(\"/\")[-1])\n",
    "            dataframe[\"genre id\"].append(genres[folder.split('/')[-1]])\n",
    "            dataframe[\"filename\"].append(file)\n",
    "            \n",
    "    dataframe=pd.DataFrame(dataframe)\n",
    "    return dataframe\n",
    "genre_names=[\"blues\",\"classical\",\"country\",\"disco\",\"pop\",\"metal\",\"jazz\",\"rock\",\"reggae\",\"hiphop\"]\n",
    "genres={name:value for name,value in zip(genre_names,[i for i in range(len(genre_names))])}\n",
    "data=dataframe_representation()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-level features\n",
    "Low-level features pertain to content-based features. The chosen content-based features along with their representations are listed below.\n",
    "- Spectral centroid (mean)\n",
    "- Spectral rolloff (std)\n",
    "- Chroma (mean)\n",
    "- Zero crossing rate (mean)\n",
    "- MFCCs (20 each represented by mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def low_level_features():\n",
    "    \n",
    "    n=len(data)\n",
    "    \n",
    "    features_dataframe={\"spectral_centroid\":np.zeros(n),\"spectral_rolloff\":np.zeros(n),\"chroma\":np.zeros(n),\n",
    "                        \"zero_crossing_rate\":np.zeros(n),\"rms_mean\":np.zeros(n),\n",
    "                       \"rms_std\":np.zeros(n)}\n",
    "    \n",
    "    for index,row in data.iterrows(): \n",
    "        x,sr=librosa.load(row[\"filename\"])\n",
    "        \n",
    "        #extract spectral centroid\n",
    "        spectral_centroid=librosa.feature.spectral_centroid(x, sr=sr)\n",
    "        features_dataframe[\"spectral_centroid\"][index]=np.std(spectral_centroid)\n",
    "        \n",
    "        #extract spectral rolloff\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(x, sr=sr)\n",
    "        features_dataframe[\"spectral_rolloff\"][index]=np.std(spectral_rolloff)\n",
    "        \n",
    "        \n",
    "        #extract chroma\n",
    "        chroma=librosa.feature.chroma_stft(x, sr=sr)\n",
    "        features_dataframe[\"chroma\"][index]=np.mean(chroma)\n",
    "        \n",
    "        #extract zero crossing rate\n",
    "        zcr=librosa.feature.zero_crossing_rate(x)\n",
    "        features_dataframe[\"zero_crossing_rate\"][index]=(np.mean(zcr))\n",
    "        \n",
    "        #extract root mean square energy\n",
    "        rms=librosa.feature.rmse(x)\n",
    "        features_dataframe[\"rms_mean\"][index]=np.mean(rms)\n",
    "        features_dataframe[\"rms_std\"][index]=np.std(rms)\n",
    "        \n",
    "#         #extract tempo\n",
    "#         onset_env = librosa.onset.onset_strength(x, sr=sr)\n",
    "#         tempo = librosa.beat.tempo(onset_envelope=onset_env, sr=sr)\n",
    "#         features_dataframe[\"tempo\"][index]=tempo[0]\n",
    "        \n",
    "        #extract mfccs (n mfccs)\n",
    "        mfccs=librosa.feature.mfcc(x, sr=sr)\n",
    "        mfccs=np.mean(mfccs,axis=1)\n",
    "        \n",
    "        for i in range(len(mfccs)):\n",
    "            key=\"mfcc\"+str(i+1)\n",
    "            if key in features_dataframe.keys():\n",
    "                features_dataframe[key][index]=(mfccs[i])\n",
    "            else:\n",
    "                features_dataframe[key]=np.zeros(n)\n",
    "                features_dataframe[key][index]=(mfccs[i])\n",
    "                \n",
    "        #extract spectral contrast\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(x, sr=sr)\n",
    "        spectral_contrast=np.mean(spectral_contrast,axis=1)\n",
    "        \n",
    "        for i in range(len(spectral_contrast)):\n",
    "            key=\"sc\"+str(i+1)\n",
    "            if key in features_dataframe.keys():\n",
    "                features_dataframe[key][index]=(spectral_contrast[i])\n",
    "            else:\n",
    "                features_dataframe[key]=np.zeros(n)\n",
    "                features_dataframe[key][index]=(spectral_contrast[i])\n",
    "                \n",
    "    features_dataframe[\"label\"]=data[\"genre id\"].values\n",
    "    features_dataframe=pd.DataFrame(features_dataframe)\n",
    "    sklearn.utils.shuffle(features_dataframe)\n",
    "    \n",
    "    return features_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.5310785   13.95174217  17.26574072  17.02327043  17.31074785\n",
      "  16.38186677  42.83155136]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song,sr=librosa.load(\"data/GTZAN/disco/disco.00075.wav\")\n",
    "spectral_contrast = librosa.feature.spectral_contrast(song, sr=sr)\n",
    "spectral_contrast=np.mean(spectral_contrast,axis=1)\n",
    "print(spectral_contrast)\n",
    "spectral_contrast.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phantom/virtualenvironment/Research_Project/lib/python3.5/site-packages/librosa/core/pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "x=low_level_features()\n",
    "x.to_csv(\"long.csv\",index=False)\n",
    "end=time.time()\n",
    "print(\"Feature extraction duration :\",end-start)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=x.loc[:,(x.columns!=\"label\") & (x.columns!=\"tempo\")].values\n",
    "Y=x.loc[:,(x.columns==\"label\") & (x.columns!=\"tempo\")].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=(X-np.mean(X,axis=0))/(np.std(X,axis=0)+1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.8411111111111111\n",
      "Test 0.7\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, Y_train.ravel())\n",
    "y_tr=neigh.predict(X_train)\n",
    "y_p=(neigh.predict(X_test))\n",
    "print(\"Train\",np.count_nonzero(y_tr==Y_train.flatten())/len(y_tr))\n",
    "print(\"Test\",np.count_nonzero(y_p==Y_test.flatten())/len(y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.5477777777777778\n",
      "Test 0.52\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_tr = gnb.fit(X_train, Y_train.ravel()).predict(X_train)\n",
    "y_pred = gnb.fit(X_train, Y_train.ravel()).predict(X_test)\n",
    "print(\"Train\",np.count_nonzero(y_tr==Y_train.flatten())/len(y_tr))\n",
    "print(\"Test\",np.count_nonzero(y_pred==Y_test.flatten())/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression OVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.754444444444\n",
      "Test 0.72\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0,solver=\"sag\",max_iter=500).fit(X_train, Y_train.ravel())\n",
    "print(\"Train\",clf.score(X_train, Y_train))\n",
    "print(\"Test\",clf.score(X_test,Y_test.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784444444444\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(activation=\"identity\",max_iter=1500,solver=\"adam\",hidden_layer_sizes=(16)).fit(X_train,Y_train.ravel(),)\n",
    "a=clf.score(X_train, Y_train.ravel())\n",
    "b=clf.score(X_test, Y_test.ravel())\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 0.8822222222222222\n",
      "Test 0.73\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.SVC()\n",
    "lin_clf.fit(X_train, Y_train.ravel())\n",
    "y_tr = lin_clf.predict(X_train)\n",
    "y_pred = lin_clf.predict(X_test)\n",
    "print(\"Train\",np.count_nonzero(y_tr==Y_train.flatten())/len(y_tr))\n",
    "print(\"Test\",np.count_nonzero(y_pred==Y_test.flatten())/len(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high-level feature would be a spectrogram obtained from the short time fourier transform of a given audio file. We may choose to compute the mel-spectrogram instead of the spectrogram. A mel-spectrogram is obtained by scaling a spectrogram to the mel-scale (pitch measure) this means that equally distances in pitch sound equally distant to the human ear. A visualization of the spectrogram and mel-spectrogram are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "audio_path='data/GTZAN/blues/blues.00002.wav'\n",
    "x,sr=librosa.load(audio_path)\n",
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "\n",
    "chroma=librosa.feature.chroma_stft(x, sr=sr)\n",
    "print(chroma.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Spectrogram\")\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Mel-spectrogram\")\n",
    "y, sr = librosa.load(audio_path)\n",
    "mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n",
    "mel_spect = librosa.power_to_db(X, ref=np.max)\n",
    "librosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def high_level_features(mode):\n",
    "    features_dataframe={}\n",
    "    if mode==\"spectrogram\":\n",
    "        audio_paths=data[\"path\"].values\n",
    "        for audio in audio_paths:\n",
    "            x,sr=librosa.load(audio)\n",
    "            X = librosa.stft(x)\n",
    "            \n",
    "            Xdb = librosa.amplitude_to_db(abs(X))\n",
    "            X_resized=image_resized = resize(Xdb,(512,512),anti_aliasing=True)\n",
    "            break\n",
    "        plt.figure()\n",
    "        plt.imshow(Xdb)\n",
    "        #librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "        plt.figure()\n",
    "        #librosa.display.specshow(X_resized, sr=sr, x_axis='time', y_axis='hz')\n",
    "        plt.imshow(X_resized)\n",
    "    pass\n",
    "\n",
    "high_level_features(\"spectrogram\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ipd.Audio(audio_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
